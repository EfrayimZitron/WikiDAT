{
 "metadata": {
  "name": "",
  "signature": "sha256:abf472b027770e6cbff0adedfdd0d74d85e131126dd528c686ee2c5f734807a0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "WikiDAT Database - SQLAlchemy ORM"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this project is to create and test the database used to store Wikipedia metadata using the SQLAlchemy tools. While SQLAlchemy is a Python SQL toolkit which provides two tools to work with databases: Core, and the Object Relational Mapper. The ORM allows databases to be described in Python as high-level object-oriented abstractions; tables in the database are associated with user-defined classes. This allows for more maintainable code that should translate relatively easily to various database engines. The Core, which contains the SQLAlchemy Expression Language, also represents databases using Python constructs, but is not as abstracted and operates at a lower level than the ORM. In fact, the ORM is built upon  the SQLAlchemy Expression Language. \n",
      "\n",
      "Using an ORM allows a user to automate much of the basic CRUD-work that accompanies database management. Without using an upper-layer abstraction, it is diffcult to efficiently bulk-query the database. Subsequently, using the ORM allows for efficient bulk insertions  or queries. However, compared to the lower-level Core, the ORM has an additional overhead  known as the Unit of Work. The Unit of Work keeps track of all changes made to database objects during a session, changes which are subsequently flushed to the databases. This bookkeeping that the ORM utilizes, which is very valuable, will invariably cause a notable decrease in performance when dealing with high-volume inserts to the database. Implementing the inserts  using SQLAlchemy Core would further optimize performance, as the Core does not implement the Unit of Work concept, and therefore does not have the additional overhead of tracking changes made to objects and the subsequent synchronization with the underlying database. Additionally, creating the  database schema in Core allows for the possibility of  eliminating primary key constraints, which can slightly improve performance.\n",
      "\n",
      "The database systems to be used in creating and testing the database are MySQL and PostgreSQL, two of the most popular database systems. MySQL is the most widely used, but it is not fully ACID-compliant by design (unless you use InnoDB), which affects transaction reliability. On the other hand, PostgreSQL is fully ACID-compliant, which is important for transaction reliability, but for simple bulk inserts and queries, such precautions are largely unnecessary and needlessly affect performance.\n",
      "\n",
      "The tests were run using both Python 2.7 as well as Python 3.4, primarily to use the MySQLdb database connector (used in the WIkiDAT source code) that is not compatible with Python 3.4 , but also to see if there would be any measurable difference in performance using a connector that is compatible with both.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementation - MySQL + ORM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initially, the database was described using the ORM, for the MySQL system. What follows are the database tables described as classes, with each attribute in the table represented as a class member. Additionally, each class has a constructor which simplifies the insertion of data when read in from CSV data dumps.\n",
      "\n",
      "The database schema, along with a detailed description of its tables/attributes, is available at:\n",
      "\n",
      "https://github.com/glimmerphoenix/WikiDAT/blob/master/wikidat/sources/db/base_schema.py\n",
      "\n",
      "All the classes are mapped using SQLAlchemy's _Declarative_ system, which defines the classes as inheriting from the a base class which all the class/tables are collected. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import Column, create_engine\n",
      "from sqlalchemy.types import SMALLINT, VARBINARY\n",
      "from sqlalchemy.dialects.mysql import INTEGER, DATETIME, TEXT, TINYINT, TINYBLOB, VARCHAR\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "import pymysql\n",
      "import sys\n",
      "\n",
      "Base = declarative_base()\n",
      "\n",
      "dbengine = 'MyISAM'  # sys.argv[1]\n",
      "params = {'mysql_engine': dbengine}\n",
      "\n",
      "\n",
      "class Page(Base):\n",
      "    __tablename__ = 'page'\n",
      "    __table_args__ = params\n",
      "    page_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    page_namespace = Column(SMALLINT, nullable=False)\n",
      "    page_title = Column(VARCHAR(length=255, binary=True), nullable=False)\n",
      "    page_restrictions = Column(TINYBLOB, nullable=False)\n",
      "\n",
      "    def __init__(self, page_id=None, page_namespace=None, page_title=None, page_restrictions=None):\n",
      "        self.page_id = page_id\n",
      "        self.page_namespace = page_namespace\n",
      "        self.page_title = page_title\n",
      "        self.page_restrictions = page_restrictions\n",
      "\n",
      "\n",
      "class Revision(Base):\n",
      "    __tablename__ = 'revision'\n",
      "    __table_args__ = params\n",
      "    rev_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    rev_page = Column(INTEGER(unsigned=True), nullable=False)\n",
      "    rev_user = Column(INTEGER(unsigned=True), nullable=False, default=0)\n",
      "    rev_timestamp = Column(DATETIME, nullable=False)\n",
      "    rev_len = Column(INTEGER(unsigned=True), nullable=False)\n",
      "    rev_parent_id = Column(INTEGER(unsigned=True), nullable=True, default= 'NULL')\n",
      "    rev_is_redirect = Column(TINYINT(display_width=1, unsigned=True), nullable=False, default=0)\n",
      "    rev_minor_edit = Column(TINYINT(display_width=1, unsigned=True), nullable=False, default=0)\n",
      "    rev_fa = Column(TINYINT(display_width=1, unsigned=True), nullable=False, default=0)\n",
      "    rev_flist = Column(TINYINT(display_width=1, unsigned=True), nullable=False, default=0)\n",
      "    rev_ga = Column(TINYINT(display_width=1, unsigned=True), nullable=False, default=0)\n",
      "    rev_comment = Column(TEXT, nullable=False)\n",
      "\n",
      "    def __init__(self, rev_id=None, rev_page=None, rev_user=None, rev_timestamp=None, rev_len=None,\n",
      "                 rev_parent_id=None, rev_is_redirect=None, rev_minor_edit=None, rev_fa=None, rev_flist=None,\n",
      "                 rev_ga=None, rev_comment=None):\n",
      "        self.rev_id = rev_id\n",
      "        self.rev_page = rev_page\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_timestamp = rev_timestamp\n",
      "        self.rev_len = rev_len\n",
      "        self.rev_parent_id = rev_parent_id\n",
      "        self.rev_is_redirect = rev_is_redirect\n",
      "        self.rev_minor_edit = rev_minor_edit\n",
      "        self.rev_fa = rev_fa\n",
      "        self.rev_flist = rev_flist\n",
      "        self.rev_ga = rev_ga\n",
      "        self.rev_comment = rev_comment\n",
      "\n",
      "\n",
      "class RevisionHash(Base):\n",
      "    __tablename__ = 'revision_hash'\n",
      "    __table_args__ = params\n",
      "    rev_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    rev_page = Column(INTEGER(unsigned=True), nullable=False)\n",
      "    rev_user = Column(INTEGER(unsigned=True), nullable=False, default=0)\n",
      "    rev_hash = Column(VARBINARY(256), nullable=False)\n",
      "\n",
      "    def __init__(self, rev_id=None, rev_page=None, rev_user=None, rev_hash=None):\n",
      "        self.rev_id = rev_id\n",
      "        self.rev_page = rev_page\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_hash = rev_hash\n",
      "\n",
      "\n",
      "class Namespaces(Base):\n",
      "    __tablename__ = 'namespaces'\n",
      "    __table_args__ = params\n",
      "    code = Column(SMALLINT, nullable=False, primary_key=True)\n",
      "    name = Column(VARCHAR(50), nullable=False)\n",
      "\n",
      "    def __init__(self, code=None, name=None):\n",
      "        self.code = code\n",
      "        self.name = name\n",
      "\n",
      "\n",
      "class People(Base):\n",
      "    __tablename__ = 'people'\n",
      "    __table_args__ = params\n",
      "    rev_user = Column(INTEGER(unsigned=True), nullable=False, default=0, primary_key=True)\n",
      "    rev_user_text = Column(VARCHAR(length=255, binary=True), nullable=True, default='')\n",
      "\n",
      "    def __init__(self, rev_user=None, rev_user_text=None):\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_user_text = rev_user_text\n",
      "\n",
      "\n",
      "class Logging(Base):\n",
      "    __tablename__ = 'logging'\n",
      "    __table_args__ = params\n",
      "    log_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    log_type = Column(VARCHAR(length=15, binary=True), nullable=False)\n",
      "    log_action = Column(VARCHAR(length=15, binary=True), nullable=False)\n",
      "    log_timestamp = Column(DATETIME, nullable=False)\n",
      "    log_user = Column(INTEGER(unsigned=True), nullable=False)\n",
      "    log_username = Column(VARCHAR(length=255, binary=True), nullable=False, default='')\n",
      "    log_namespace = Column(INTEGER(display_width=5), nullable=False, default=0)\n",
      "    log_title = Column(VARCHAR(length=255, binary=True), nullable=False, default='')\n",
      "    log_comment = Column(VARCHAR(length=255, binary=True), nullable=False, default='')\n",
      "    log_params = Column(VARCHAR(length=255, binary=True), nullable=False, default='')\n",
      "    log_new_flag = Column(INTEGER(unsigned=True), nullable=False, default=0)\n",
      "    log_old_flag = Column(INTEGER(unsigned=True), nullable=False)\n",
      "\n",
      "    def __init__(self, log_id=None, log_type=None, log_action=None, log_timestamp=None, log_user=None,\n",
      "                 log_username=None, log_namespace=None, log_title=None, log_comment=None, log_params=None,\n",
      "                 log_new_flag=None, log_old_flag=None):\n",
      "        self.log_id = log_id\n",
      "        self.log_type = log_type\n",
      "        self.log_action = log_action\n",
      "        self.log_timestamp = log_timestamp\n",
      "        self.log_user = log_user\n",
      "        self.log_username = log_username\n",
      "        self.log_namespace = log_namespace\n",
      "        self.log_title = log_title\n",
      "        self.log_comment = log_comment\n",
      "        self.log_params = log_params\n",
      "        self.log_new_flag = log_new_flag\n",
      "        self.log_old_flag = log_old_flag\n",
      "\n",
      "\t\t\n",
      "class Block(Base):\n",
      "    __tablename__ = 'block'\n",
      "    __table_args__ = params\n",
      "    block_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    block_action = Column(VARCHAR(length = 15, binary = True), nullable=False)\n",
      "    block_user = Column(INTEGER(unsigned=True), nullable=False)\n",
      "    block_timestamp = Column(DATETIME, nullable=False)\n",
      "    block_target = Column(INTEGER, nullable=False)\n",
      "    block_ip = Column(INTEGER(display_width= 10, unsigned=True), nullable= False)\n",
      "    block_duration = Column(INTEGER(unsigned=True), nullable=False)\n",
      "\n",
      "    def __init__(self, block_id=None, block_action = None, block_user=None, block_timestamp =None, block_target=None,\n",
      "                 block_ip=None, block_duration=None):\n",
      "        self.block_id = block_id\n",
      "        self.block_action = block_action\n",
      "        self.block_user = block_user\n",
      "        self.block_timestamp = block_timestamp\n",
      "        self.block_target = block_target\n",
      "        self.block_ip = block_ip\n",
      "        self.block_duration = block_duration\n",
      "   \n",
      "class NewUser(Base):\n",
      "    __tablename__ = 'newuser'\n",
      "    __table_args__ = params\n",
      "    user_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    username = Column(VARCHAR(length = 255), nullable=False)\n",
      "    user_timestamp = Column(DATETIME, nullable=False)\n",
      "    user_action = Column(VARCHAR(15), nullable=False)\n",
      "\n",
      "    def __init__(self, user_id=None, username = None, user_timestamp=None,user_action=None):\n",
      "        self.user_id = user_id\n",
      "        self.username = username\n",
      "        self.user_timestamp = user_timestamp\n",
      "        self.user_action = user_action\n",
      "\n",
      "\t\t\n",
      "class Right(Base):\n",
      "    __tablename__ = 'right'\n",
      "    __table_args__ = params\n",
      "    right_id = Column(INTEGER(unsigned=True), nullable=False, primary_key=True)\n",
      "    right_username = Column(VARCHAR(length = 255), nullable=False)\n",
      "    right_timestamp = Column(DATETIME, nullable=False)\n",
      "    right_old = Column(VARCHAR(length = 255), nullable=False)\n",
      "    right_new = Column(VARCHAR(length = 255), nullable=False)\n",
      "\n",
      "    def __init__(self, right_id=None, right_username = None, right_timestamp=None, right_old=None, right_new = None):\n",
      "        self.right_id = right_id\n",
      "        self.right_username = right_username\n",
      "        self.right_timestamp = right_timestamp\n",
      "        self.right_old = right_old\n",
      "        self.right_new = right_new"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, the database and tables are created using either the PyMySQL database connector, or the MySQLdb connector . Both are libraries used to connect to the MySQL server, with the caveat that MySQLdb is a C extension, while PyMySQL is pure-python. PyMySQL has the benefit of working with verious Python implementations as well as being fully compatible with Python 2 and 3, while MySQLdb has yet to release a Python 3 compatible version of the connector"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('mysql+pymysql://root:@localhost/')\n",
      "#engine = create_engine('mysql+mysqldb://root:@localhost/')\n",
      "engine.execute(\"DROP DATABASE IF EXISTS wikidb\")\n",
      "engine.execute(\"CREATE DATABASE IF NOT EXISTS wikidb CHARACTER SET utf8 COLLATE utf8_general_ci\")  # create db\n",
      "engine.execute(\"USE wikidb\")\n",
      "Base.metadata.create_all(engine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing - MySQL + ORM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next phase was to test the performance of this setup. This was done by inserting ~250k rows of data into 3 of the tables. The breakdown is as follows:\n",
      "\n",
      "* Page: 70,242 rows\n",
      "* Revision: 93,594 rows\n",
      "* Revision_Hash: 93,594 rows\n",
      "\n",
      "The test were performed using both InnoDB and MyISAM storage engines. As expected, MyISAM performed better, due to the absence of ACID-compliancy and its subsequent overhead. The results of these tests as well as the upcoming ones are at the end of the document.\n",
      "\n",
      "The following code is written for Python 3. There are a few changes that need to be made before running in Python 2, which are commented out.\n",
      "\n",
      "For this relatively small amount of data, it was not inefficient to first read all of the data into lists, which were then iterated over many times to test the performance of bulk inserts. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loads data from csv file into a list (of lists)\n",
      "\n",
      "#with open('page.csv') as f:                                          #Python 2\n",
      "with open('page.csv', newline='', encoding='utf-8') as f:             #Python 3\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    page_data = list(list(row) for row in reader)\n",
      "\n",
      "#with open('revision.csv') as f:                                      #Python 2\n",
      "with open('revision.csv', newline='', encoding='utf-8') as f:         #Python 3\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_data = list(list(row) for row in reader)\n",
      "\n",
      "#with open('revision_hash.csv') as f:                                 #Python 2\n",
      "with open('revision_hash.csv', newline='', encoding='utf-8') as f:    #Python 3\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_hash_data = list(list(row) for row in reader)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _load_  funtion purpose is to iterate over each list and commit the data to the database. In this situation, due to the fact that less than 100k rows of data were being inserted per table, it was sufficient to commit after each list had finished iterating. For larger data sets, which could cause memory issues, it would probably be necessary to perform periodic commits (period would vary on the machine used)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load():\n",
      "    for item in page_data:\n",
      "        session.add(dbschema_orm.Page(*item))\n",
      "    session.commit()\n",
      "\n",
      "    for item in revision_data:\n",
      "        session.add(dbschema_orm.Revision(*item))\n",
      "    session.commit()\n",
      "\n",
      "    for item in revision_hash_data:\n",
      "        session.add(dbschema_orm.RevisionHash(*item))\n",
      "    session.commit() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to calculate the speed of the inserts, the timer module was used on the _load_ function. The _run_time_test_ function drops all the tables, re-creates them, then runs and times the _load_ function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Timer calculates how much time it takes for the data to be loaded into the database.\n",
      "timer = timeit.Timer(stmt='load()', setup='from __main__ import load')\n",
      "\n",
      "# Had to specify that the timer should only run one execution of the code since multiple runs of inserting identical\n",
      "# data would fail due to primary key violations\n",
      "def run_time_test():\n",
      "    dbschema_orm.Base.metadata.drop_all(engine)\n",
      "    dbschema_orm.Base.metadata.create_all(engine)\t\n",
      "    return(timer.timeit(number=1))\n",
      "\t\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the engine is created to connect to the database (using PyMySQL in this snippet), and the inserts run as many times as determined by the argument provided on the command line. The performance time of each run is recorded, as well as the resulting fastest time and the average time. For these tests, 100 runs for each database/connector/python variation were performed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " # Have to append '/?charset=utf8' to the create_engine string since there were encoding errors (UnicodeEncodeErrors) without it\n",
      "engine = create_engine('mysql+pymysql://root:@localhost/?charset=utf8')\n",
      "engine.execute(\"USE wikidb\")\n",
      "Session = sessionmaker(bind=engine)\n",
      "session = Session()\n",
      "\n",
      "total = []\n",
      "\n",
      "#Python 3\n",
      "for x in range(int(sys.argv[1])):\n",
      "\ttotal.append(run_time_test())\n",
      "\tprint ('Run', x, 'took', total[x])\n",
      "\n",
      "print ('The fastest run was:', min(total), 'secs')\n",
      "print ('Average running time:', sum(total)/len(total), 'secs')\n",
      "print ('Standard Deviation:', statistics.stdev(total), 'secs')\n",
      "\n",
      "#Python 2\n",
      "\"\"\" \n",
      "for x in range(int(sys.argv[1])):                      \n",
      "\ttotal.append(run_time_test())                       \n",
      "\tprint 'Run', x, 'took', total[x]\n",
      "\n",
      "print 'The fastest run was:', min(total), 'secs'\n",
      "print 'Average running time:', sum(total)/len(total), 'secs'\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementation - MySQL + Core"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implementing the schema using SQLAlchemy Expression Language would further optimize inserts, as the Core does not require the use of primary keys in the schema. Using the  Core for inserts aloows for drastic performance increase since it does not implement the Unit of Work, and therefore does not have the additional overhead of tracking changes made to objects and the subsequent synchronization with the underlying database. The tables are not defined as classes as in the ORM, but as groups of Column ojects. The database metadata is represented by the aggregate of all the table objects in the script.\n",
      "\n",
      "An important note is that no attribute has been established as a primary key in any of the tables, in order to avoid contraint checking which could reduce performance slightly. This was not possible using the ORM, due to the fact that as a feature of the Unit of Work system, the ORM requires a primary key in each table to accurately associate in-memory rows with thei corresonding rows in the database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import Table, Column, MetaData\n",
      "from sqlalchemy.types import SMALLINT, VARBINARY\n",
      "from sqlalchemy.dialects.mysql import INTEGER, DATETIME, TEXT, TINYINT, TINYBLOB, VARCHAR\n",
      "from sqlalchemy import create_engine\n",
      "import pymysql\n",
      "import sys\n",
      "\n",
      "metadata = MetaData()\n",
      "\n",
      "dbengine = 'MyISAM'  # sys.argv[1]\n",
      "\n",
      "\n",
      "page = Table('page', metadata,\n",
      "    Column('page_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('page_namespace', SMALLINT, nullable=False),\n",
      "    Column('page_title', VARCHAR(length=255, binary=True), nullable=False),\n",
      "    Column('page_restrictions', TINYBLOB, nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\n",
      "revision = Table('revision', metadata,\n",
      "    Column('rev_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('rev_page', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('rev_user', INTEGER(unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_timestamp', DATETIME, nullable=False),\n",
      "    Column('rev_len', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('rev_parent_id', INTEGER(unsigned=True), nullable=True, default = 'Null'),\n",
      "    Column('rev_is_redirect', TINYINT(display_width=1, unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_minor_edit', TINYINT(display_width=1, unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_fa', TINYINT(display_width=1, unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_flist', TINYINT(display_width=1, unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_ga', TINYINT(display_width=1, unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_comment', TEXT, nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\n",
      "revision_hash = Table('revision_hash', metadata,\n",
      "    Column('rev_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('rev_page', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('rev_user', INTEGER(unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_hash', VARBINARY(256), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\n",
      "namespaces = Table('namespaces', metadata,\n",
      "    Column('code', SMALLINT, nullable=False),\n",
      "    Column('name', VARCHAR(50), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\n",
      "people = Table('people', metadata,\n",
      "    Column('rev_user', INTEGER(unsigned=True), nullable=False, default=0),\n",
      "    Column('rev_user_text', VARCHAR(length=255, binary=True), nullable=True, default=''),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\n",
      "logging = Table('logging', metadata,\n",
      "    Column('log_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('log_type', VARCHAR(length=15, binary=True), nullable=False),\n",
      "    Column('log_action', VARCHAR(length=15, binary=True), nullable=False),\n",
      "    Column('log_timestamp', DATETIME, nullable=False),\n",
      "    Column('log_user', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('log_username', VARCHAR(length=255, binary=True), nullable=False, default=''),\n",
      "    Column('log_namespace', INTEGER(display_width=5), nullable=False, default=0),\n",
      "    Column('log_title', VARCHAR(length=255, binary=True), nullable=False, default=''),\n",
      "    Column('log_comment', VARCHAR(length=255, binary=True), nullable=False, default=''),\n",
      "    Column('log_params', VARCHAR(length=255, binary=True), nullable=False, default=''),\n",
      "    Column('log_new_flag', INTEGER(unsigned=True), nullable=False, default=0),\n",
      "    Column('log_old_flag', INTEGER(unsigned=True), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\t\n",
      "block = Table('block', metadata,\n",
      "    Column('block_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('block_action', VARCHAR(length = 15, binary = True), nullable=False),\n",
      "    Column('block_user', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('block_timestamp', DATETIME, nullable=False),\n",
      "    Column('block_target', INTEGER, nullable=False),\n",
      "    Column('block_ip', INTEGER(display_width= 10, unsigned=True), nullable= False),\n",
      "    Column('block_duration', INTEGER(unsigned=True), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\t\n",
      "new_user = Table('new_user', metadata,\n",
      "    Column('user_id',INTEGER(unsigned=True), nullable=False),\n",
      "    Column('username', VARCHAR(length = 255), nullable=False),\n",
      "    Column('user_timestamp', DATETIME, nullable=False),\n",
      "    Column('user_action', VARCHAR(15), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\n",
      "\t\n",
      "right = Table('right', metadata,\n",
      "    Column('right_id', INTEGER(unsigned=True), nullable=False),\n",
      "    Column('right_username', VARCHAR(length = 255), nullable=False),\n",
      "    Column('right_timestamp', DATETIME, nullable=False),\n",
      "    Column('right_old', VARCHAR(length = 255), nullable=False),\n",
      "    Column('right_new', VARCHAR(length = 255), nullable=False),\n",
      "    mysql_engine= dbengine)\n",
      "\t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Database and tables are created using either the PyMySQL database connector or MySQLdb connector."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('mysql+pymysql://root:@localhost/')\n",
      "#engine = create_engine('mysql+mysqldb://root:@localhost/')\n",
      "engine.execute(\"DROP DATABASE IF EXISTS wikidb\")\n",
      "engine.execute(\"CREATE DATABASE IF NOT EXISTS wikidb CHARACTER SET utf8 COLLATE utf8_general_ci\")  # create db\n",
      "engine.execute(\"USE wikidb\")\n",
      "metadata.create_all(engine)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing - MySQL + Core"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(identical testing conditions as before)\n",
      "The next phase was to test the performance of this setup. This was done by inserting ~250k rows of data into 3 of the tables. The breakdown is as follows:\n",
      "\n",
      "* Page: 70,242 rows\n",
      "* Revision: 93,594 rows\n",
      "* Revision_Hash: 93,594 rows\n",
      "\n",
      "The test were performed using both InnoDB and MyISAM storage engines. As expected, MyISAM performed better, due to the absence of ACID-compliancy and its subsequent overhead. The results of these tests as well as the upcoming ones are at the end of the document.\n",
      "\n",
      "The following code is written for Python 3. There are a few changes that need to be made before running in Python 2, which are commented out.\n",
      "\n",
      "SQLAlchemy Core implements handles insert statements differently than the ORM, so each row of the CSV file is read as a dictionary instea dof a list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#with open('page.csv', \"rb\") as page_file:                                                 #Python 2\n",
      "with open('page.csv', newline = '' , encoding = 'utf-8') as page_file:                     #Python 3\n",
      "\tfieldnames = ('page_id', 'page_namespace', 'page_title', 'page_restrictions')\n",
      "\treader = csv.DictReader(page_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "\tpage_dict = [row for row in reader]\n",
      "\t\n",
      "\n",
      "#with open('revision.csv', \"rb\") as page_file:                                             #Python 2\n",
      "with open('revision.csv', newline = '' , encoding = 'utf-8') as revision_file:             #Python 3\n",
      "\tfieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_timestamp', 'rev_len', 'rev_parent_id',\n",
      "\t\t\t\t  'rev_is_redirect', 'rev_minor_edit', 'rev_fa', 'rev_flist', 'rev_ga', 'rev_comment')\n",
      "\treader = csv.DictReader(revision_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "\trevision_dict = [row for row in reader]\n",
      "\n",
      "#with open('revision_hash.csv', \"rb\") as page_file:                                        #Python 2\n",
      "with open('revision_hash.csv', newline = '' , encoding = 'utf-8') as revision_hash_file:   #Python 3\n",
      "\tfieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_hash')\n",
      "\treader = csv.DictReader(revision_hash_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "\trevision_hash_dict = [row for row in reader]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _load_ function inserts the data, using DB API's executemany() method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load():\n",
      "\n",
      "\tengine.execute(dbschema_core.page.insert(),page_dict)\n",
      "\n",
      "\tengine.execute(dbschema_core.revision.insert(),revision_dict)\n",
      "\n",
      "\tengine.execute(dbschema_core.revision_hash.insert(),revision_hash_dict)\t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to calculate the speed of the inserts, the timer module was used on the load function. The run_time_test function drops all the tables, re-creates them, then runs and times the load function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timer = timeit.Timer(stmt='load()', setup='from __main__ import load')\n",
      "\n",
      "def run_time_test():\n",
      "    dbschema_core.metadata.drop_all(engine)\n",
      "    dbschema_core.metadata.create_all(engine)\t\n",
      "    return(timer.timeit(number=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the engine is created to connect to the database (using PyMySQL in this snippet), and the inserts run as many times as determined by the argument provided on the command line. The performance time of each run is recorded, as well as the resulting fastest time and the average time. For these tests, 100 runs for each database/connector/python variation were performed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('mysql+pymysql://root:@localhost/?charset=utf8')\n",
      "engine.execute(\"USE wikidb\")\n",
      "\n",
      "total = []\n",
      "\n",
      "#Python 3\n",
      "for x in range(int(sys.argv[1])):\n",
      "\ttotal.append(run_time_test())\n",
      "\tprint ('Run', x, 'took', total[x])\n",
      "\n",
      "print ('The fastest run was:', min(total), 'secs')\n",
      "print ('Average running time:', sum(total)/len(total), 'secs')\n",
      "print ('Standard Deviation:', statistics.stdev(total), 'secs')\n",
      "\n",
      "#Python 2\n",
      "\"\"\" \n",
      "for x in range(int(sys.argv[1])):                      \n",
      "\ttotal.append(run_time_test())                       \n",
      "\tprint 'Run', x, 'took', total[x]\n",
      "\n",
      "print 'The fastest run was:', min(total), 'secs'\n",
      "print 'Average running time:', sum(total)/len(total), 'secs'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementation - PostgreSQL + Core"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Due to Postgres not being fully compatible with all MySQL data types, some attributes' data type were changed to the Postrgres equivalent (or at least close enough)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import Table, Column, MetaData, text\n",
      "from sqlalchemy.types import VARBINARY, DateTime\n",
      "from sqlalchemy.dialects.postgresql import  TEXT, BYTEA, BOOLEAN, SMALLINT\n",
      "from sqlalchemy.dialects.mysql import VARCHAR, INTEGER\n",
      "from sqlalchemy import create_engine\n",
      "import psycopg2\n",
      "import sys\n",
      "\n",
      "#Create metadata object which will hold table info\n",
      "metadata = MetaData()\n",
      "\n",
      "page = Table('page', metadata,\n",
      "    Column('page_id', INTEGER, nullable=False),\n",
      "    Column('page_namespace', SMALLINT, nullable = False),\n",
      "    Column('page_title', VARCHAR(length=255, binary=True), nullable=False),\n",
      "    Column('page_restrictions', BYTEA(256), nullable=False, server_default=''))\n",
      "\n",
      "\t\n",
      "revision = Table('revision', metadata,\n",
      "    Column('rev_id', INTEGER, nullable=False),\n",
      "    Column('rev_page', INTEGER, nullable=False),\n",
      "    Column('rev_user', INTEGER, nullable=False, server_default= text('0')),\n",
      "    Column('rev_timestamp', DateTime, nullable=False),\n",
      "    Column('rev_len', INTEGER, nullable=False),\n",
      "    Column('rev_parent_id', INTEGER, nullable=True, server_default = text('NULL')),\n",
      "    Column('rev_is_redirect', BOOLEAN, nullable=False, server_default='0'),\n",
      "    Column('rev_minor_edit', BOOLEAN, nullable=False, server_default='0'),\n",
      "    Column('rev_fa', BOOLEAN, nullable=False, server_default='0'),\n",
      "    Column('rev_flist', BOOLEAN, nullable=False, server_default='0'),\n",
      "    Column('rev_ga', BOOLEAN, nullable=False, server_default='0'),\n",
      "    Column('rev_comment', TEXT, nullable=False))\n",
      "\n",
      "\t\n",
      "revision_hash = Table('revision_hash', metadata,\n",
      "    Column('rev_id', INTEGER, nullable=False),\n",
      "    Column('rev_page', INTEGER, nullable=False),\n",
      "    Column('rev_user', INTEGER, nullable=False, server_default = text('0')),\n",
      "    Column('rev_hash', BYTEA(256), nullable=False))\n",
      "\n",
      "\t\n",
      "namespaces = Table('namespaces', metadata,\n",
      "    Column('code', SMALLINT, nullable=False),\n",
      "    Column('name', VARCHAR(50), nullable=False))\n",
      "\n",
      "\t\n",
      "people = Table('people', metadata,\n",
      "    Column('rev_user', INTEGER, nullable=False, server_default= text('0')),\n",
      "    Column('rev_user_text', VARCHAR(length=255, binary=True), nullable=True, server_default=''))\n",
      "\n",
      "\t\n",
      "logging = Table('logging', metadata,\n",
      "    Column('log_id', INTEGER, nullable=False),\n",
      "    Column('log_type', VARCHAR(length=15, binary=True), nullable=False),\n",
      "    Column('log_action', VARCHAR(length=15, binary=True), nullable=False),\n",
      "    Column('log_timestamp', DateTime, nullable=False),\n",
      "    Column('log_user', INTEGER, nullable=False),\n",
      "    Column('log_username', VARCHAR(length=255, binary=True), nullable=False, server_default=''),\n",
      "    Column('log_namespace', INTEGER(display_width=5), nullable=False, server_default = text('0')),\n",
      "    Column('log_title', VARCHAR(length=255, binary=True), nullable=False, server_default=''),\n",
      "    Column('log_comment', VARCHAR(length=255, binary=True), nullable=False, server_default=''),\n",
      "    Column('log_params', VARCHAR(length=255, binary=True), nullable=False, server_default=''),\n",
      "    Column('log_new_flag', INTEGER, nullable=False, server_default=text('0')),\n",
      "    Column('log_old_flag', INTEGER, nullable=False))\n",
      "\n",
      "\n",
      "block = Table('block', metadata,\n",
      "    Column('block_id', INTEGER, nullable=False),\n",
      "    Column('block_action', VARCHAR(length = 15, binary = True), nullable=False),\n",
      "    Column('block_user', INTEGER, nullable=False),\n",
      "    Column('block_timestamp', DateTime, nullable=False),\n",
      "    Column('block_target', INTEGER, nullable=False),\n",
      "    Column('block_ip', INTEGER, nullable= False),\n",
      "    Column('block_duration', INTEGER, nullable=False))\n",
      "\n",
      "\t\n",
      "new_user = Table('new_user', metadata,\n",
      "    Column('user_id',INTEGER, nullable=False),\n",
      "    Column('username', VARCHAR(length = 255), nullable=False),\n",
      "    Column('user_timestamp', DateTime, nullable=False),\n",
      "    Column('user_action', VARCHAR(length = 15), nullable=False))\n",
      "\n",
      "\t\n",
      "right = Table('right', metadata,\n",
      "    Column('right_id', INTEGER, nullable=False),\n",
      "    Column('right_username', VARCHAR(length = 255), nullable=False),\n",
      "    Column('right_timestamp', DateTime, nullable=False),\n",
      "    Column('right_old', VARCHAR(length = 255), nullable=False),\n",
      "    Column('right_new', VARCHAR(length = 255), nullable=False))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tables are created using using the psycopg connector. A recurring error required the database itself to be created manually."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('postgresql+psycopg2://postgres:root@localhost/wikidb')\n",
      "conn = engine.connect()\n",
      "metadata.drop_all(conn)\n",
      "metadata.create_all(conn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing - PostgreSQL + Core"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(identical testing conditions as before)\n",
      "The next phase was to test the performance of this setup. This was done by inserting ~250k rows of data into 3 of the tables. The breakdown is as follows:\n",
      "\n",
      "* Page: 70,242 rows\n",
      "* Revision: 93,594 rows\n",
      "* Revision_Hash: 93,594 rows\n",
      "\n",
      "The following code is written for Python 3. There are a few changes that need to be made before running in Python 2, which are commented out.\n",
      "\n",
      "Due to encoding issues, the BYTEA data types had to be converted from Unicode strings to byte strings. Becuase of the way Python 2 opens files, this was not an issue in Python 2. However in both Python 2 and 3, occurences of 'NULL' as a value for rev_parent_id had to removed, since 'NULL' is not a valid integer value in Postgres."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('page.csv', newline = '' , encoding = 'utf-8') as page_file:\t\t\t\n",
      "    fieldnames = ('page_id', 'page_namespace', 'page_title', 'page_restrictions')\n",
      "    reader = csv.DictReader(page_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    page_dict = []\n",
      "    for row in reader:\n",
      "        row['page_restrictions'] =  row['page_restrictions'].encode('utf-8')\n",
      "        page_dict.append(row) \n",
      "    \n",
      "with open('revision.csv', newline = '' , encoding = 'utf-8') as revision_file:\t\t\t#Py 3\n",
      "    fieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_timestamp', 'rev_len', 'rev_parent_id',\n",
      "                  'rev_is_redirect', 'rev_minor_edit', 'rev_fa', 'rev_flist', 'rev_ga', 'rev_comment')\n",
      "    reader = csv.DictReader(revision_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    revision_dict = []\n",
      "    for row in reader:\n",
      "        if row['rev_parent_id'] == 'NULL':\n",
      "            row['rev_parent_id'] = None \n",
      "        revision_dict.append(row)\n",
      "\n",
      "with open('revision_hash.csv', newline = '' , encoding = 'utf-8') as revision_hash_file:\t\t#Py 3\n",
      "    fieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_hash')\n",
      "    reader = csv.DictReader(revision_hash_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    revision_hash_dict = []\n",
      "    for row in reader:\n",
      "        row['rev_hash'] =  row['rev_hash'].encode('utf-8')\n",
      "        revision_hash_dict.append(row)\n",
      "        \n",
      "\"\"\" Python 2\n",
      "\n",
      "with open('page.csv', \"rb\") as page_file:\n",
      "    fieldnames = ('page_id', 'page_namespace', 'page_title', 'page_restrictions')\n",
      "    reader = csv.DictReader(page_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    page_dict = [row for row in reader]\n",
      "    \n",
      "\n",
      "with open('revision.csv', \"rb\") as revision_file:\n",
      "    fieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_timestamp', 'rev_len', 'rev_parent_id',\n",
      "                  'rev_is_redirect', 'rev_minor_edit', 'rev_fa', 'rev_flist', 'rev_ga', 'rev_comment')\n",
      "    reader = csv.DictReader(revision_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    revision_dict = []\n",
      "    for row in reader:\n",
      "        if row['rev_parent_id'] == 'NULL':\n",
      "            row['rev_parent_id'] = None \n",
      "        revision_dict.append(row)\n",
      "\n",
      "with open('revision_hash.csv', \"rb\") as revision_hash_file:\n",
      "    fieldnames = ('rev_id', 'rev_page', 'rev_user', 'rev_hash')\n",
      "    reader = csv.DictReader(revision_hash_file, fieldnames = fieldnames, delimiter='\\t')\n",
      "    revision_hash_dict = [row for row in reader]\n",
      "    \n",
      "\"\"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _load_ function inserts the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load():\n",
      "    engine.execute(dbschema_core_postgresql.page.insert(),page_dict)\n",
      "\t\n",
      "    engine.execute(dbschema_core_postgresql.revision.insert(),revision_dict)\n",
      "\n",
      "    engine.execute(dbschema_core_postgresql.revision_hash.insert(),revision_hash_dict) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to calculate the speed of the inserts, the timer module was used on the load function. The run_time_test function drops all the tables, re-creates them, then runs and times the load function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timer = timeit.Timer(stmt='load()', setup='from __main__ import load')\n",
      "\n",
      "def run_time_test():\n",
      "    dbschema_core_postgresql.metadata.drop_all(engine)\n",
      "    dbschema_core_postgresql.metadata.create_all(engine)    \n",
      "    return(timer.timeit(number=1))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the engine is created to connect to the database, and the inserts run as many times as determined by the argument provided on the command line. The performance time of each run is recorded, as well as the resulting fastest time and the average time. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('postgresql+psycopg2://postgres:root@localhost/wikidb')\n",
      "\n",
      "total = []\n",
      "\n",
      "for x in range(int(sys.argv[1])):\n",
      "    total.append(run_time_test())\n",
      "    print ('Run', x, 'took', total[x], 'secs')\n",
      "    \n",
      "\t\t\t\t\n",
      "print ('The fastest run was:', min(total), 'secs')\t\t\t\t\t\n",
      "print ('Average running time:', statistics.mean(total), 'secs')\t\t\n",
      "print ('Standard Deviation:', statistics.stdev(total), 'secs')\t\n",
      "\n",
      "\n",
      "#Python 2\n",
      "\"\"\" \n",
      "for x in range(int(sys.argv[1])):                      \n",
      "\ttotal.append(run_time_test())                       \n",
      "\tprint 'Run', x, 'took', total[x]\n",
      "\n",
      "print 'The fastest run was:', min(total), 'secs'\n",
      "print 'Average running time:', sum(total)/len(total), 'secs'\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Implementation - PostgreSQL + ORM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import Column, create_engine, text\n",
      "from sqlalchemy.types import VARBINARY, DateTime\n",
      "from sqlalchemy.dialects.postgresql import  TEXT, BYTEA, BOOLEAN, SMALLINT\n",
      "from sqlalchemy.dialects.mysql import VARCHAR, INTEGER\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "import psycopg2\n",
      "import sys\n",
      "\n",
      "Base = declarative_base()\n",
      "\n",
      "dbengine = 'InnoDB'  # sys.argv[1]\n",
      "params = {'mysql_engine': dbengine}\n",
      "\n",
      "\n",
      "class Page(Base):\n",
      "    __tablename__ = 'page'\n",
      "    __table_args__ = params\n",
      "    page_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    page_namespace = Column(SMALLINT, nullable=False)\n",
      "    page_title = Column(VARCHAR(length=255, binary=True), nullable=False)\n",
      "    page_restrictions = Column(BYTEA(256), nullable=False, server_default='')\n",
      "\n",
      "    def __init__(self, page_id=None, page_namespace=None, page_title=None, page_restrictions=None):\n",
      "        self.page_id = page_id\n",
      "        self.page_namespace = page_namespace\n",
      "        self.page_title = page_title\n",
      "        self.page_restrictions = page_restrictions\n",
      "\n",
      "\n",
      "class Revision(Base):\n",
      "    __tablename__ = 'revision'\n",
      "    __table_args__ = params\n",
      "    rev_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    rev_page = Column(INTEGER, nullable=False)\n",
      "    rev_user = Column(INTEGER, nullable=False, default=0)\n",
      "    rev_timestamp = Column(DateTime, nullable=False)\n",
      "    rev_len = Column(INTEGER, nullable=False)\n",
      "    rev_parent_id = Column(INTEGER, nullable=True, server_default = text('NULL'))\n",
      "    rev_is_redirect = Column(BOOLEAN, nullable=False, server_default='0')\n",
      "    rev_minor_edit = Column(BOOLEAN, nullable=False, server_default='0')\n",
      "    rev_fa = Column(BOOLEAN, nullable=False, server_default='0')\n",
      "    rev_flist = Column(BOOLEAN, nullable=False, server_default='0')\n",
      "    rev_ga = Column(BOOLEAN, nullable=False, server_default='0')\n",
      "    rev_comment = Column(TEXT, nullable=False)\n",
      "\n",
      "    def __init__(self, rev_id=None, rev_page=None, rev_user=None, rev_timestamp=None, rev_len=None,\n",
      "                 rev_parent_id=None, rev_is_redirect=None, rev_minor_edit=None, rev_fa=None, rev_flist=None,\n",
      "                 rev_ga=None, rev_comment=None):\n",
      "        self.rev_id = rev_id\n",
      "        self.rev_page = rev_page\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_timestamp = rev_timestamp\n",
      "        self.rev_len = rev_len\n",
      "        self.rev_parent_id = rev_parent_id\n",
      "        self.rev_is_redirect = rev_is_redirect\n",
      "        self.rev_minor_edit = rev_minor_edit\n",
      "        self.rev_fa = rev_fa\n",
      "        self.rev_flist = rev_flist\n",
      "        self.rev_ga = rev_ga\n",
      "        self.rev_comment = rev_comment\n",
      "\n",
      "\n",
      "class RevisionHash(Base):\n",
      "    __tablename__ = 'revision_hash'\n",
      "    __table_args__ = params\n",
      "    rev_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    rev_page = Column(INTEGER, nullable=False)\n",
      "    rev_user = Column(INTEGER, nullable=False, server_default = text('0'))\n",
      "    rev_hash = Column(BYTEA(256), nullable=False)\n",
      "\n",
      "    def __init__(self, rev_id=None, rev_page=None, rev_user=None, rev_hash=None):\n",
      "        self.rev_id = rev_id\n",
      "        self.rev_page = rev_page\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_hash = rev_hash\n",
      "\n",
      "\n",
      "class Namespaces(Base):\n",
      "    __tablename__ = 'namespaces'\n",
      "    __table_args__ = params\n",
      "    code = Column(SMALLINT, nullable=False, primary_key=True)\n",
      "    name = Column(VARCHAR(50), nullable=False)\n",
      "\n",
      "    def __init__(self, code=None, name=None):\n",
      "        self.code = code\n",
      "        self.name = name\n",
      "\n",
      "\n",
      "class People(Base):\n",
      "    __tablename__ = 'people'\n",
      "    __table_args__ = params\n",
      "    rev_user = Column(INTEGER, nullable=False, server_default= text('0'), primary_key=True)\n",
      "    rev_user_text = Column(VARCHAR(length=255, binary=True), nullable=True,  server_default='')\n",
      "\n",
      "    def __init__(self, rev_user=None, rev_user_text=None):\n",
      "        self.rev_user = rev_user\n",
      "        self.rev_user_text = rev_user_text\n",
      "\n",
      "\n",
      "class Logging(Base):\n",
      "    __tablename__ = 'logging'\n",
      "    __table_args__ = params\n",
      "    log_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    log_type = Column(VARCHAR(length=15, binary=True), nullable=False)\n",
      "    log_action = Column(VARCHAR(length=15, binary=True), nullable=False)\n",
      "    log_timestamp = Column(DateTime, nullable=False)\n",
      "    log_user = Column(INTEGER, nullable=False)\n",
      "    log_username = Column(VARCHAR(length=255, binary=True), nullable=False, server_default='')\n",
      "    log_namespace = Column(INTEGER(display_width=5), nullable=False, server_default = text('0'))\n",
      "    log_title = Column(VARCHAR(length=255, binary=True), nullable=False, server_default='')\n",
      "    log_comment = Column(VARCHAR(length=255, binary=True), nullable=False,server_default='')\n",
      "    log_params = Column(VARCHAR(length=255, binary=True), nullable=False, server_default='')\n",
      "    log_new_flag = Column(INTEGER, nullable=False, server_default=text('0'))\n",
      "    log_old_flag = Column(INTEGER, nullable=False)\n",
      "\n",
      "    def __init__(self, log_id=None, log_type=None, log_action=None, log_timestamp=None, log_user=None,\n",
      "                 log_username=None, log_namespace=None, log_title=None, log_comment=None, log_params=None,\n",
      "                 log_new_flag=None, log_old_flag=None):\n",
      "        self.log_id = log_id\n",
      "        self.log_type = log_type\n",
      "        self.log_action = log_action\n",
      "        self.log_timestamp = log_timestamp\n",
      "        self.log_user = log_user\n",
      "        self.log_username = log_username\n",
      "        self.log_namespace = log_namespace\n",
      "        self.log_title = log_title\n",
      "        self.log_comment = log_comment\n",
      "        self.log_params = log_params\n",
      "        self.log_new_flag = log_new_flag\n",
      "        self.log_old_flag = log_old_flag\n",
      "\n",
      "\t\t\n",
      "class Block(Base):\n",
      "    __tablename__ = 'block'\n",
      "    __table_args__ = params\n",
      "    block_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    block_action = Column(VARCHAR(length = 15, binary = True), nullable=False)\n",
      "    block_user = Column(INTEGER, nullable=False)\n",
      "    block_timestamp = Column(DateTime, nullable=False)\n",
      "    block_target = Column(INTEGER, nullable=False)\n",
      "    block_ip = Column(INTEGER(display_width= 10), nullable= False)\n",
      "    block_duration = Column(INTEGER, nullable=False)\n",
      "\n",
      "    def __init__(self, block_id=None, block_action = None, block_user=None, block_timestamp =None, block_target=None,\n",
      "                 block_ip=None, block_duration=None):\n",
      "        self.block_id = block_id\n",
      "        self.block_action = block_action\n",
      "        self.block_user = block_user\n",
      "        self.block_timestamp = block_timestamp\n",
      "        self.block_target = block_target\n",
      "        self.block_ip = block_ip\n",
      "        self.block_duration = block_duration\n",
      "   \n",
      "class NewUser(Base):\n",
      "    __tablename__ = 'newuser'\n",
      "    __table_args__ = params\n",
      "    user_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    username = Column(VARCHAR(length = 255), nullable=False)\n",
      "    user_timestamp = Column(DateTime, nullable=False)\n",
      "    user_action = Column(VARCHAR(15), nullable=False)\n",
      "\n",
      "    def __init__(self, user_id=None, username = None, user_timestamp=None,user_action=None):\n",
      "        self.user_id = user_id\n",
      "        self.username = username\n",
      "        self.user_timestamp = user_timestamp\n",
      "        self.user_action = user_action\n",
      "\n",
      "\t\t\n",
      "class Right(Base):\n",
      "    __tablename__ = 'right'\n",
      "    __table_args__ = params\n",
      "    right_id = Column(INTEGER, nullable=False, primary_key=True)\n",
      "    right_username = Column(VARCHAR(length = 255), nullable=False)\n",
      "    right_timestamp = Column(DateTime, nullable=False)\n",
      "    right_old = Column(VARCHAR(length = 255), nullable=False)\n",
      "    right_new = Column(VARCHAR(length = 255), nullable=False)\n",
      "\n",
      "    def __init__(self, right_id=None, right_username = None, right_timestamp=None, right_old=None, right_new = None):\n",
      "        self.right_id = right_id\n",
      "        self.right_username = right_username\n",
      "        self.right_timestamp = right_timestamp\n",
      "        self.right_old = right_old\n",
      "        self.right_new = right_new\t\t\t\n",
      "\t\t\n",
      "\n",
      "engine = create_engine('postgresql+psycopg2://postgres:root@localhost/wikidb')\n",
      "Base.metadata.drop_all(engine)\n",
      "Base.metadata.create_all(engine)\n",
      "\t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Testing - PostgreSQL + ORM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(identical testing conditions as before)\n",
      "The next phase was to test the performance of this setup. This was done by inserting ~250k rows of data into 3 of the tables. The breakdown is as follows:\n",
      "\n",
      "* Page: 70,242 rows\n",
      "* Revision: 93,594 rows\n",
      "* Revision_Hash: 93,594 rows\n",
      "\n",
      "The following code is written for Python 3. There are a few changes that need to be made before running in Python 2, which are commented out.\n",
      "\n",
      "Due to encoding issues, the BYTEA data types had to be converted from Unicode strings to byte strings. Becuase of the way Python 2 opens files, this was not an issue in Python 2. However in both Python 2 and 3, occurences of 'NULL' as a value for rev_parent_id had to removed, since 'NULL' is not a valid integer value in Postgres."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker\n",
      "import psycopg2\n",
      "import csv\n",
      "import sys\n",
      "import dbschema_orm_postgresql\n",
      "import timeit\n",
      "import statistics\n",
      "\n",
      " #loads data from csv file into a list (of lists)\n",
      "with open('page.csv', newline='', encoding='utf-8') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    page_data = []\n",
      "    for row in reader:\n",
      "        row[3] =  row[3].encode('utf-8')\n",
      "        page_data.append(row) \t\n",
      "\n",
      "with open('revision.csv', newline='', encoding='utf-8') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_data = []\n",
      "    for row in reader:\n",
      "        if row[5] == 'NULL':\n",
      "            row[5] = None \n",
      "        revision_data.append(row)\n",
      "\n",
      "with open('revision_hash.csv', newline='', encoding='utf-8') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_hash_data = []\n",
      "    for row in reader:\n",
      "        row[3] =  row[3].encode('utf-8')\n",
      "        revision_hash_data.append(row) \n",
      "        \n",
      "        \n",
      "        \n",
      "\"\"\"\n",
      "Python 2\n",
      "with open('page.csv') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    page_data = list(list(row) for row in reader) \t\n",
      "\n",
      "with open('revision.csv') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_data = []\n",
      "    for row in reader:\n",
      "        if row[5] == 'NULL':\n",
      "            row[5] = None \n",
      "        revision_data.append(row)\n",
      "\n",
      "with open('revision_hash.csv') as f:\n",
      "    reader = csv.reader(f, delimiter='\\t')\n",
      "    revision_hash_data = list(list(row) for row in reader)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The _load_ function loads the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load():\n",
      "    for item in page_data:\n",
      "        session.add(dbschema_orm_postgresql.Page(*item))\n",
      "    session.commit()\n",
      "\n",
      "    for item in revision_data:\n",
      "        session.add(dbschema_orm_postgresql.Revision(*item))\n",
      "    session.commit()\n",
      "\n",
      "    for item in revision_hash_data:\n",
      "        session.add(dbschema_orm_postgresql.RevisionHash(*item))\n",
      "    session.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to calculate the speed of the inserts, the timer module was used on the load function. The run_time_test function drops all the tables, re-creates them, then runs and times the load function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timer = timeit.Timer(stmt='load()', setup='from __main__ import load')\n",
      "\n",
      "def run_time_test():\n",
      "    dbschema_orm_postgresql.Base.metadata.drop_all(engine)\n",
      "    dbschema_orm_postgresql.Base.metadata.create_all(engine)\t\n",
      "    return(timer.timeit(number=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the engine is created to connect to the database, and the inserts run as many times as determined by the argument provided on the command line. The performance time of each run is recorded, as well as the resulting fastest time and the average time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "engine = create_engine('postgresql+psycopg2://postgres:root@localhost/wikidb')\n",
      "Session = sessionmaker(bind=engine)\n",
      "session = Session()\n",
      "\n",
      "total = []\n",
      "\t\n",
      "for x in range(int(sys.argv[1])):\n",
      "\ttotal.append(run_time_test())\n",
      "\tprint ('Run', x, 'took', total[x])\n",
      "\n",
      "print ('The fastest run was:', min(total), 'secs')\n",
      "print ('Average running time:', sum(total)/len(total), 'secs')\n",
      "print ('Standard Deviation:', statistics.stdev(total), 'secs')\n",
      "\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Python 2\n",
      "\n",
      "total = []\n",
      "\t\n",
      "for x in range(int(sys.argv[1])):\n",
      "\ttotal.append(run_time_test())\n",
      "\tprint 'Run', x, 'took', total[x]\n",
      "\n",
      "print 'The fastest run was:', min(total), 'secs'\n",
      "print 'Average running time:', sum(total)/len(total), 'secs'\n",
      "\t\n",
      "    \n",
      "    \n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"fastest-mysql.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"average-mysql.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Postgres"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"postgres.png\">"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}